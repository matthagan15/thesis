#import "macros.typ": *
#import "conf.typ": *

#heading("Conclusion", level: 1, supplement: "Chapter") <ch_conclusion>

After 30+ years of intense theoretic development, the most advanced end-to-end pipeline we have for utilizing potential quantum computers beyond the capabilities of classical computers is the simulation of quantum systems. Factoring large integers via Shor's algorithm is one provable advantage, assuming standard complexity theoretic conjectures such as `BQP` $!=$ `BPP`, but the advent of lattice-based cryptosystems implies that using quantum computers solely for factoring integers has decreasing utility as the time to reach thousands of logical qubits grows. Many other provable end-to-end quantum speedups, such as Grover's algorithm for unstructured search or Brandao's Semi-Definite Program solver, only offer quadratic improvements over classical techniques. Evidence suggests that these speedups would have to be applied to unfeasibly large instance sizes in order for these speedups to provide an incentive to build a quantum device. Recent efforts have also explored larger polynomial improvements, such as the quadratic improvement for planted noisy $k$XOR problem @schmidhuber2024quarticquantumspeedupsplanted, but progress remains sparse. There exist other exponential speedups for problems such as Glued Trees traversal or Sunflower graph traversal, but these problems are relatively contrived and are not very applicable. The most difficult to analyze speedups are those that rely only on existing classical algorithms, such as normalized Betti number estimation for clique homology @berry2024analyzing, optimization, and linear systems solving.

In this thesis, we presented two new quantum algorithms that can be added to the quantum simulation pipeline. The first is an extension of product formulas to include both random and deterministic sections. We were able to provide generic conditions on when these composite simulations can provide advantages over their constituent methods. We find that systems where the strength of the Hamiltonian terms decays exponentially, i.e. if $H = sum_i H_i$ then $norm(H_i) prop 2^(-i)$, have a relatively large parameter window for improvement. This conclusion was verified numerically for small systems. Further, this algorithm was extended to imaginary time evolution and provides new avenues for improving classical estimations of quantum observables.

The second contribution we make is an algorithm for preparing thermal states $e^(-beta H) / tr(e^(-beta H))$.
